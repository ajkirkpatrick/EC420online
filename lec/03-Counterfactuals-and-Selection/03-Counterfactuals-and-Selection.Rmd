---
title: "Counterfactuals and Selection Bias"
subtitle: "EC420 MSU Online"
author: "Justin Kirkpatrick"
date: "Last updated `r format(Sys.Date(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    yolo: false
    css: [default, metropolis, metropolis-fonts, "EC420_SS21.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
   
                
      

---
```{r setup, include=FALSE}

#          browseURL('https://raw.githack.com/')
#          browseURL('https://github.com/ajkirkpatrick/EC420MSU')



options(htmltools.dir.version = FALSE)
options("getSymbols.warning4.0"=FALSE)


library(here) # creates absolute paths, but those won't work in html
library(knitr)
library(kableExtra)
library(tidyverse)
library(wooldridge)
require(lubridate)
require(scales)
require(broom)
require(visualize)

require(wbstats)
require(lmtest)
require(sandwich)
require(car)
require(quantmod)
require(patchwork)



# https://yihui.org/knitr/options/
opts_chunk$set(
  fig.align="center",
  #dpi=300, 
  fig.path='figs/', # where figs are rendered
  cache=F,
  echo=F,
  message = F,
  warning = F
  )

oldgraphics = "C:/Users/jkirk/OneDrive - Michigan State University/Teaching/EC420MSU/graphics"
dir.create('img')
  
# A vital function to take an absolute path and copy the image into a local img folder.
# # Solves the issue where the rendered html wasn't pointing to the right things. 
# ## Wrap path into includ_graphics() like so:

    #     include_graphics(copy_to_include(path = "C:/Users/jkirk/OneDrive - Michigan State University/Teaching/EC420online/img/MMfig43a.png"))
copy_to_include<-function(path){
  filename.to.use = basename(path)
  if(!grepl('png$|PNG$|jpg$|JPG$', filename.to.use)) stop('Not a png or jpg')

  file.copy(from = path, to = paste0('img/',filename.to.use))
  return(paste0('img/',filename.to.use))
}

```

layout: true

<div class="msu-header"></div>  


<div style = "position:fixed; visibility: hidden">
$$\require{color}\definecolor{yellow}{rgb}{1, 0.8, 0.16078431372549}$$
$$\require{color}\definecolor{orange}{rgb}{0.96078431372549, 0.525490196078431, 0.203921568627451}$$
$$\require{color}\definecolor{MSUgreen}{rgb}{0.0784313725490196, 0.52156862745098, 0.231372549019608}$$
</div>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      yellow: ["{\\color{yellow}{#1}}", 1],
      orange: ["{\\color{orange}{#1}}", 1],
      MSUgreen: ["{\\color{MSUgreen}{#1}}", 1]
    },
    loader: {load: ['[tex]/color']},
    tex: {packages: {'[+]': ['color']}}
  }
});
</script>

<style>
.yellow {color: #FFCC29;}
.orange {color: #F58634;}
.MSUGreen {color: #14853B;}
</style>


```{r flair_color, echo=FALSE}
library(flair)
yellow <- "#FFCC29"
orange <- "#F58634"
MSUGreen <- "#14853B"
```
---

class: inverseMSU
name: Overview

# This Deck  

### __Lectures:__
(1) [Motivation](#section1)

(2) [Counterfactuals](#section2)

(3) [Potential Outcomes Framework](#section3)

- [ATE](#ATEdef)

(4) [Selection Bias](#section4)

(5) [Randomization and Experiments](#section5)

(6) [Distribution of the estimator and Gauss-Markov for MLR](#section6)

(7) [Heteroskedasticity](#section7)

(8) [Testing Multiple $\beta$'s](#section8)





---



class: heading-slide
name: section1

Motivation

### [top](#Overview)


---
class: MSU
# This unit

### What does it look like when $E[u|X]\neq 0$?

### Counterfactuals
- Define counterfactual, treatment

- Introduce notation for counterfactuals
  - Potential outcomes framework
  
### Selection Bias
- Define

- Examples

---
class: MSU
# This unit

### Course goals review
1. Understand core statistical concepts (OLS, t-tests and other tests)
2. Read, digest, and be critical of economic papers
3. Think critically about causality
4. Code in R with Rmarkdown  
5. Learn current econometric models for causality
6. Design research questions

  
---
class: heading-slide
name: section2

Counterfactuals

### [top](#Overview)




---
class: inverseMSU
name: Counterfactual 
# Counterfactuals


```{r, out.width = '90%'}

include_graphics(copy_to_include(file.path(oldgraphics, 'Frost_tworoads_full.jpg')))

```

.font50[Image credit: [Book, Tea, and Sympathy](https://ninamor2013.wordpress.com/2014/04/03/the-road-not-taken-robert-frost/)]
 


---
class: MSU
# Counterfactuals

## Intuitive meaning

- The _counterfactual_ is the outcome that _would be observed_ had something else occurred.
  - Frost longs to know what _would have resulted_ from choosing the other road

- Implies that a _counterfactual_ is defined by:
  1. An outcome that has more than one potential value
  2. A choice or occurrance that may change the realization of the outcome
  
Let's call that "choice or occurrance" the **treatment**.

  

---
class: MSU
# Counterfactuals
 
So, in the case of Robert Frost's poem:

- Outcome is, well, vague, which is the point of the poem.
  - But...we do know that he is looking at the difference of _some_ outcome between roads he could have taken.

- The "choice or occurrance" that changed the (vague) outcome is the choosing of the "less traveled" road

Or, think of the two potential outcomes from a medical treatment - outcome with the drug, and outcome without.
--

### The important point here is that __you do not get to observe both outcomes in reality__

- You can speculate, you can make comparisons, but you never get to see both (or all) counterfactuals.

- Ol' Bob Frost thinks he knows both.

---
class: MSU
# Counterfactuals

In a way, when we run a regression, we .orange[pretend] like we know both as well:

$$LifeExp = \beta_0 + \beta_1 cigarettes + \beta_2 1(exercises) + u$$

- If we plug in $0$ for $exercises$, we get the $E[LifeExp|exercises==0]$.
  
- If we plug in $1$ for $exercises$, we get $E[LifeExp|exercises==1]$

- $\beta_2$ is the difference in expected life expectancy associated with exercising

- We *identify* this in our regression by having data on people who do exercise, and data on people who don't exercise.
  - And people who smoke a lot, and people who don't smoke at all...
  - **And** we assume that all the other things in $u$ follow $E[u|cigarettes, exercise] = 0$
  
---
class: MSU
# Counterfactuals

### What would it look like if $exercises$ were in the error term?

$$LifeExp = \tilde{\beta}_0 + \tilde{\beta}_1 cigarettes + \underbrace{\tilde{u}}_{\beta_2 1(exercises) + v}$$
Where $v$ is actually a truly random error term ( $E[v|X]=0$ ).

### .red[Q:] Do we think that $exercises$ (in $E[\tilde{u}]$ ) is uncorrelated with $cigarettes$ ( $X$ )?

--

### .red[Q:] If not, what is the **relationship** between $E[\tilde{u}]$ and $X$?

---
class: MSU
# Counterfactuals

### If we run the naive regression, we can fit the line:

```{r, echo=F, include=T, fig.width = 8, fig.height = 5, out.width='75%', warning=FALSE}
require(purrr)
logg<-function(x){exp(x)/(1+exp(x))} 

NN = 1000

delta1 = -.3
beta0 = 60
beta1 = -1
beta2 = 8
df1 = data.frame(cigarettes = abs(rnorm(NN, 5, 3))) %>%
  dplyr::mutate(exercises = logg(delta1*cigarettes - mean(delta1*cigarettes)) > .5) %>%
  dplyr::mutate(v = rnorm(NN, 0, 8)) %>%
  dplyr::mutate(utilde = v + beta2*exercises) %>%
  dplyr::mutate(LifeExp = 60 + beta1*cigarettes + utilde)


ggplot(df1, aes(x = cigarettes, y = LifeExp)) + geom_point(col='red', alpha=.30) + geom_smooth(method='lm', col='gray50', se=FALSE) + theme_bw()

```

**This line is drawn assuming that** $E[\tilde{u}|X]=0$
- That is, assuming $E[\underbrace{\beta_2 1(exercises) + v}_{\tilde{u}} | cigarettes] = 0$


---
class: MSU
# Counterfactuals

### But what if we acknowledge that $E[\tilde{u}|X]\neq0$

We would need to account for the $E[\tilde{u}]\neq 0$ when $X$ is larger
- $E[\tilde{u}]$ is "exercises" and $X$ is cigarettes
- We would think $E[\tilde{u}]$ is negatively correlated with $X$

If we think about including that "wedge", we'd put out line of best fit in a different place.
- Of course, we would have to know $E[\tilde{u}|X]$ to actually correct
- So let's pretend for a moment

---
class: MSU
# Counterfactuals


```{r, echo=F, include=T, fig.width = 8, fig.height = 5, out.width='75%'}
ExpectedUDiffMult = lm(utilde ~ cigarettes, df1)$coefficients[2]
df1$ExpectedUDiff = ExpectedUDiffMult*df1$cigarettes


p = ggplot(df1, aes(x = cigarettes)) + geom_point(aes(y = LifeExp), col='red', alpha=.3, shape=16, size=2) + geom_point(aes(y = LifeExp-ExpectedUDiff), col='blue', alpha=.30, shape=17, size=2) + geom_smooth(aes(y = LifeExp, x = cigarettes), method='lm', col='red', se=FALSE) + theme_bw()

p

```

- The red dots are the given data, plotting $LifeExp \sim cigarettes$
- The blue triangles are where the points **would be if we could account for** $E[\tilde{u}|X]\neq 0$
- Here, $E[\tilde{u}|X] = `r round(lm(utilde ~ cigarettes, df1)$coefficients[2], 2)` \times cigarettes$

---
class: MSU
# Counterfactuals

```{r, echo=F, include=T, fig.width = 8, fig.height = 5, out.width='75%'}
p +  geom_smooth(method='lm', aes(y = LifeExp-ExpectedUDiff, x = cigarettes), col='blue', se=FALSE)
```

If we draw the line using the blue points which **account for the (unobserved) relationship between $u$ and $cigarettes$**, then we get a different slope (the blue line).

The red line is the same as the blue line **if and only if** $E[\tilde{u}|X]=0$. 

---
class: MSU
# Counterfactuals

```{r, fig.width = 8, fig.height = 5, out.width='75%', echo=F}
p +  geom_smooth(method='lm', aes(y = LifeExp-ExpectedUDiff, x = cigarettes), col='blue', se=FALSE)
```

**So** if we observe one person who smokes a lot, and one who smokes very little, in order to say that the effect of smoking is the difference between the two, we have to be able to say we've accounted for everything else.

---
class: MSU
# Counterfactuals

```{r, fig.width = 8, fig.height = 5, out.width='70%', echo=F}
p +  geom_smooth(method='lm', aes(y = LifeExp-ExpectedUDiff, x = cigarettes), col='blue', se=FALSE)
```

**If** we had the same person (so all $u$ are the same), but we could see that person "with" and "without" smoking, we wouldn't have to worry, right? $exercise$ would be the **same**, so would everything else in $\tilde{u}$


---
class: MSU
# Counterfactuals

### So...
- Counterfactuals are closely related to our MLR.4 $E[u|X] = 0$
- Having a valid counterfactual is like knowing that everything in $u$ is the same when the "treatment" is different

---
class: heading-slide
name: section3

Potential Outcomes Framework

<br>
### [top](#Overview)








---
class: MSU
# Potential outcomes


### The "potential outcomes" notation (Rubin, 1974)

- Let $Y$ be our outcome
  - $Y_i$ is individual $i$'s outcome

- Let $D$ be the __treatment__ variable.
  - $D_i = 1$ if $i$ is "treated"
  - $D_i = 0$ if $i$ is "not treated"
    - Later, we'll talk about what happens if "treatment" is not 0/1 (binary)
    
- Let $X$ be the observable characteristics (e.g. $X_i$)
  
---

class: MSU
# Potential outcomes

### $Y$ has some potential outcomes:
We will index them (tell them apart) using a subscipt

- Let $Y_{1i}$ be the outcome _if_ $Y_i$ is treated (if $D_i = 1$)
- Let $Y_{0i}$ be the outcome _if_ $Y_i$ is not treated (if $D_i = 0$)
  
Then, we can write:
$$Y_i= \begin{cases}
    Y_{1i} ,& \text{if } D = 1\\
    Y_{0i} ,& \text{if } D = 0
\end{cases}$$

---
class: MSU
# Potential outcomes

### What do we want to know?

What we'd like to know is $Y_{1i} - Y_{0i}$, individual $i$'s difference in outcomes with and without treatments, which is the _causal effect of the treatment_ for $i$.

- Remember, _every_ $i$ has two potential outcomes.

--

For Robert Frost: $Y_{1i} - Y_{0i} = \text{''all''}$

--

But isn't there a problem here? How do we know $Y_{1i}$ **and** $Y_{0i}$?

We only see one, not both.

We could try looking beyond a single $i$, right? But that causes problems, as we saw in the previous example with $cigarettes$ and $exercises$

---
class: MSU
# Potential outcomes


### Just as before, the function $E$ is the _expectation_ function. 

$E[Y]$ is the expectation of $Y$

$E[Y] = \frac{1}{N_{pop}} \sum^{N_{pop}}_{n=1} Y_n$, which is the _population average_.

Of course, we don't usually observe the full population, so we use _sample average_ instead.

When the _sample average_ is used, MM will usually write $\hat{E}[Y]$ or $E_n[Y]$

---
class: MSU
# Potential outcomes

### Conditional expectations

- Let $E[Y]$ be the expected outcome

- Let $E[Y|D=1]$ be the expected outcome if treated
  - Read this as "Expectation of Y _conditional on_ D equaling 1"
  
- Let $E[Y|D=0]$ be the expected outcome if untreated
  - Read this as "Expectation of Y _conditional on_ D equaling 0"

--

This leads to some intuitive combinations:

- $E[Y_0 | D = 0]$ and $E[Y_1 | D = 1]$ are what we observe

And some not-so-intuitive combinations:

- $E[Y_1 | D = 0]$ and $E[Y_0 | D = 1]$ (these __are not observed__)

--

- Let's think about what these really mean, as they will come up again.
  
 
---
class: MSU
name: ATEdef
# Potential outcomes

### What do we really want to know

Unless we are $i$, we'd actually really like to know the population analog: $E[Y_{1} - Y_{0}]$ 

### This is the __Average Treatment Effect, or ATE__ 
- $ATE=E[Y_1 - Y_0]$

We could calculate this by taking the expectation of the causal effect of treatment: $E_{i}[Y_{1i} - Y_{0i}] = \frac{1}{N}\sum_{i=1}^{N_{pop}} Y_{1i} - Y_{0i}$

But that means we need to know _both_ $Y_{1i}$ and $Y_{0i}$ for each and every $i$. Getting the __ATE__ has the same issue as getting the causal effect: __we don't observe the counterfactual__



---
class: MSU
# Potential outcomes

### Why would we want to know this?

Imagine that $D$ is a drug. Then $E[Y_1 - Y_0]$ is the drug's .orange[population] effect. 

- If $Y$ is the number of years surviving after a medical diagnosis, then the _ATE_, $E[Y_1 - Y_0]$ is the expected increase in years of survival.

### Let's define another treatment effect: SATE

__SATE__ is the _Selected average treatment effect_, the _ATE for those that receive treatment_.

_SATE_ = $E[Y_1 - Y_0 | D = 1]$

This might not be quite as useful as the _ATE_, but under certain assumptions, they are the same. Specifically, under the *constant-effects assumption* (MM, p.10)

---
class: MSU
# Potential outcomes

### The **SATE**

The **SATE** also requires that we observe both $Y_{1i}$ and $Y_{0i}$ for each $i$.

How about we make an assumption:
- We observe some individual $i$ where $D=1$ and thus we observe $Y_{1i}$
- We observe some other individual $j$ where $D=0$ and thus we observe $Y_{0j}$
- Let's pretend $i$ and $j$ are interchangable and we compare $E[Y_{1}] - E[Y_{0}]$! 

We've got some $Y_1$'s and some $Y_0$'s, so we have:
- $E[Y|D=1]=E[Y_1|D=1]$
- $E[Y|D=0]=E[Y_0|D=0]$




---
class: heading-slide
name: section4


Selection Bias

<br><br>
### [top](#Overview)





---
class: MSU
# Selection bias

### **Selection bias** occurs when the people who get treated (have $D=1$) have .orange[different values] for $Y_{1i}$ and $Y_{0i}$ from those who do not get treatment

--
<br><br>

### Put formally: $(Y_{1i}, Y_{0i}) \perp D$

That is, the .orange[potential] outcomes are **independent** of treatment




---
class: MSU
name: SATE

# Selection bias
We observe $E[Y|D=1]$ and $E[Y|D=0]$

$$\begin{eqnarray}\small
&& E[Y | D = 1] - E[Y | D = 0] \\
&=&  E[Y_1 | D=1] - E[Y_0 | D = 0] \\
                            &=& E[Y_1 | D=1] - E[Y_0 | D = 0] - E[Y_0 | D=1] + E[Y_0 | D=1] \\
                            &=& E[Y_1 | D=1] - E[Y_0 | D = 1] + E[Y_0 | D=1] - E[Y_0 | D=0] \\
                            &=& \underbrace{E[(Y_1 - Y_0) | D=1]}_\text{SATE} + \underbrace{E[Y_0|D=1] - E[Y_0|D=0]}_\text{selection bias}
\end{eqnarray}$$
The first equality is based on the definition of what we observe.

The second is just subtracting and adding $E[Y_0 | D=1]$, which cancels out.

The fourth is using the definition of conditional - two expectations that are conditional on the same thing can be combined.

The last is from the definition of SATE (and introduces the definition of __"selection bias"__).
 

---
class: MSU
# Selection bias

### What is bias in general?

In this context, bias can be thought of as anything that distorts a statistic of interest like the _ATE_, _SATE_, or population mean.

$E[W]\neq \theta$

### What is selection bias?
Selection bias is the distortion that is included when we try to infer a population causal effect from differences in observed outcomes (e.g. what we did before).

Selection bias is a "bias" because it biases our estimate of the thing we want: population SATE.


$$\underbrace{E[Y|D=1] - E[Y|D=0]}_{\text{Observed Comparison of Means}} \neq \underbrace{E[Y_1 - Y_0|D=1]}_{\text{SATE, the thing we want}}$$


---
class: MSU
# Selection bias

### What are the common sources of selection bias?
This can occur if:
- Treatment is assigned in some way that is associated with potential outcomes
  - Treatment is given to people with higher $Y_{1i}$
  - Optimizing behavior can lead to this
- Treatment is self-selected
  - If people are allowed to "select in" to treatment
  - Esp. if they know their potential outcomes
  - E.g. the "smokers at the hospital" example



Note that traditionally, "selection bias" refers to non-random sampling (e.g. you survey people outside of a senior citizens home on their age, and use that to estimate a population average age - it'll be biased!)


---
class: MSU
# Selection bias

### Some examples of selection bias

If we are interested in the effect of college on earnings...
- We would worry that the sort of people who select into college do so because they know they have a high $Y_{1i}$, where the treatment is "attending college".
  
If we are interested in the effect of a drug on expected survival time...
- We would worry that people who select to take a drug might have very bad (low) values of $Y_{0i}$, the outcome without the drug, and thus "select in" to treatment. Without the drug, they would have a much worse (lower) survival expectancy than those who do not select in to treatment. If we compare the average survival of the treated to the untreated, we will not get a useful measure.

---
class: MSU
# Selection bias


If we are interested in the effect of health insurance on some health outcome...
- We would worry that people who have insurance might have very different potential health outcomes. For one, people who purchase insurance tend to have higher income, and higher income earners tend to have better health regardless of insurance. $Y_{0i} > Y_{0j}$ when $income_i > income_j$.

---
class: MSU
# Selection bias

### Some examples of selection bias

If we are interested in the effect of smoking on probability of stroke (and we ignore age)...
  - What would the treatment and control groups be defined by?
  - Would there be any reason people would "select" into a group?
  - Would there be any reason to think there would be a selection bias?

---
class: MSU
# Selection bias

### Formally, selection bias occurs when
$$E[Y_0 | D = 1] - E[Y_0 | D = 0] \neq 0$$
Which is when 

$$E[Y_0 | D=1] \neq E[Y_0 | D=0]$$

The potential outcome associated with no treatment is different for those who are treated relative to those who are otherwise untreated.

Another way of saying this is that treatment $D$ is **not** independent of the values of $(Y_{1i}, Y_{0i}$)
- $(Y_{1i}, Y_{0i}) \not\perp D$

And, $E[Y_0 | D=1]$ is never observed, so we cannot just subtract off the selection bias from our naive comparison of means: $E[Y|D=1] - E[Y|D=0]$.


---
class: MSU
# Selection bias

To summarize, when we do a comparison of means:

$$E[Y|D=1] - E[Y|D=0]$$

we get the .DUKEblue[SATE] + .red[Selection Bias:]

$$\color{blue}{E[Y_1 - Y_0 | D=1]} + \color{red}{E[Y_0 | D=1] - E[Y_0 | D= 0]}$$


And when we regress $y = \beta_0 + \beta_1 D + u$, we are doing a "comparison of means"

---
class: MSU
# Selection bias 

### Another example:

Imagine we have an energy conservation program where a homeowner has someone come to their home and show them their energy consumption, as well as ways they can save electricity. We would want to know the treatment effect of this program - maybe policymakers want to know how effective it is. Or maybe we have a theory that costly information keeps homeowners from consuming a more efficient amount of energy.

---
class: MSU
# Selection bias

 
.pull-left[
Our sample is four people.

```{r, echo=F, include=T}

df = data.frame(Name = c('Allison','Bertrand','Carmine','Dalia'),
                Treated = c(T,T,F,F),
                Energy_Use_Without = c(4,5,3,4),
                Energy_Use_With = c(3,4,2,3))

knitr::kable(df %>% dplyr::select(-Treated), format='html', col.names = c('Name','Use Without Tmt','Use With Tmt'), align=c('lcc')) %>% 
  column_spec(column = 1, border_right=T, bold=T) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, font_size=18)

```
.font60[Unrealistic data (we observe both potential outcomes)]

]

.pull-right[
- Here we get to *unrealistically* observe both outcomes $Y_{i0}$ **and** $Y_{i1}$

- Define the [Average Treatment Effect](#ATEdef)?

- Calculate the Average Treatment Effect here.


]


---
class: MSU
# Selection bias
 


.pull-left[
Our sample is four people.

```{r, include=T, echo=F}
knitr::kable(df, format='html', col.names = c('Name','Treated','Use Without Tmt','Use With Tmt'), align=c('lccc')) %>% 
  column_spec(column = 1, border_right=T, bold=T) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, font_size=18)

```
.font60[Unrealistic data (we observe both potential outcomes)]
]

.pull-right[
- Allison and Bertrand are "treated"; we observe their "Use With" values

- Carmine and Dalia are "untreated"; we observe only their "Use Without" values
]

---
class: MSU
# Selection bias

First, let's be naive. Let's look at the average use **of those who received the treatment** and compare it to the average use **of those who did not**, $E[Y|D=1] - E[Y|D=0]$


.center[
| Name | Treated | Observed |
|:---|:---:|:---:|
|**Allison**|TRUE|`r df[1,4]`|
|**Bertrand**|TRUE|`r df[2,4]`|
|**Carmine**|FALSE|`r df[3,3]`|
|**Dalia**|FALSE|`r df[4,3]`|
]

--
Why might the naive estimate not be the same as the ATE (or the SATE)

---
class: MSU
# Selection bias


### Why does our naive comparison of means not yield the (S)ATE?

--

### Let's draw this on the board

---
class: clear

---
class: MSU
# Selection bias

Now, we've seen **selection bias** in action, and we showed that it is part of what we get from a naive comparison of means [using algebra on conditional expectations](#SATE)

How would we test to see if our "treated" group is different from our "untreated" group?
- If we observed both before and after for each individual, we could **still** use a naive comparison of means **if** the before and after consumption were just about equal.

--

- Is it just about equal in the example?

- What if we didn't get to observe the "before" for each $i$? 

--

### Covariate balance
All the other things we observe along with the outcome are our *covariates*.

We might hope that we would have "just about equal" values for the (unobserved) before if all those covariates were "just about equal" too. 

---
class: MSU
# Selection bias

```{r, out.width = '50%'}
include_graphics(copy_to_include(file.path(oldgraphics,'MM_Tables_Figures', 'MMtbl13.png')))#
# <html><img src="MMtbl13.png" style="width: 90%"/></html>
```


---
class: MSU
# Selection bias

Unfortunately, covariate balance makes a weak case about the balance of the unobserved factors (like the "before" consumption).

A lack of balance does make a strong case *against* balance in the unobserved factors.
- "Necessary but not sufficient"

We do have tools to let us *control* for differences. 


---
class: MSU
# Wrap-up

The main takeaways from the last few lectures:
1. Every $i$ has two potential outcomes
2. We don't get to see both of them
3. A counterfactual is the "what would have been"
4. The ATE is a population parameter
5. It is usually what we're after
6. We can use the $E[\cdots]$ notation to formalize our estimates
7. Doing so lets us see where selection bias may occur
8. Lack of balance in covariates may indicate presence of a selection bias
9. Balance in covariates does not indicate lack of selection bias










---
class: heading-slide
name: section5

Randomization and Experiments


<br>
### [top](#Overview)



---
class: MSU
# Randomization

You are going to randomly assign treatment to the four people on the [next slide](#data):
- First, randomly decide to which group each member belongs.
  - Use `sample(c(T,F), size = 4, replace=T)` to randomly draw 4 treatment assignments in a vector
  - `TRUE` means that person is treated and we'll use their "with treatment" value, `FALSE` means the opposite
  
- Second, build a new observed dataset with the randomly realized observed values
  - Use the "with" value for that person if the person is randomly placed in the with-treatment
  - Use "without" value for that person if the person is randomly placed in the without-treatment
  
- Third, calculate the group means and the difference between the group means.
  - Repeat 15 times.
  
We want to see how this comparison of means between the with-treatment and without-treatment groups does in estimating the $ATE$.


---
class: MSU
name: data
# Randomization



```{r , include=T, echo=F}
knitr::kable(df %>% dplyr::select(-Treated), format='html', col.names = c('Name','Use Without Tmt','Use With Tmt'), align=c('lcc')) %>% 
  column_spec(column = 1, border_right=T, bold=T) %>%
  kable_styling(bootstrap_options = "striped", full_width = T, font_size=18)
```

 


---
class: MSU

# Randomization

### Report the 15 trial results: the mean with, the mean without, and the difference between means

--

### Calculate the average over all the randomized trials. What is the average with- and without-treatment value? What is the average difference?

--

### What was our previous result comparing the means?

--

### We know that the Average Treatment Effect is 1. Which one is closer to the true value of 1?

---
class: MSU
# Randomization

## Randomization (of treatment) eliminates selection bias

Let's see if we can show this *formally*....


---
class: MSU
# Randomization

Recall that in a previous lecture, we used some algebra on conditional expectations to *decompose* the naive difference in means into two parts:


$$\begin{eqnarray}\small
&& E[Y | D = 1] - E[Y | D = 0] \\
&=&  E[Y_1 | D=1] - E[Y_0 | D = 0] \\
                            &=& E[Y_1 | D=1] - E[Y_0 | D = 0] - E[Y_0 | D=1] + E[Y_0 | D=1] \\
                            &=& E[Y_1 | D=1] - E[Y_0 | D = 1] + E[Y_0 | D=1] - E[Y_0 | D=0] \\
                            &=& \underbrace{E[(Y_1 - Y_0) | D=1]}_\text{SATE} + \underbrace{E[Y_0|D=1] - E[Y_0|D=0]}_\text{selection bias}
\end{eqnarray}$$



---
class: MSU
# Randomization



$$\begin{eqnarray}\small
&& E[Y | D = 1] - E[Y | D = 0] \\
&=&  E[Y_1 | D=1] - E[Y_0 | D = 0] \\
                            &=& E[Y_1 | D=1] - E[Y_0 | D = 0] - E[Y_0 | D=1] + E[Y_0 | D=1] \\
                            &=& E[Y_1 | D=1] - E[Y_0 | D = 1] + E[Y_0 | D=1] - E[Y_0 | D=0] \\
                            &=& \underbrace{E[(Y_1 - Y_0) | D=1]}_\text{SATE} + \underbrace{E[Y_0|D=1] - E[Y_0|D=0]}_\text{selection bias}
\end{eqnarray}$$

Now, we saw that randomization got us closer to the correct answer. It might even be unbiased! But what does randomization do?
- It randomly assigns treatment

--

- So what would $E[Y_0|D=1]$ be if treatment, $D$, is random? It would be:


$$E[Y_0|D=1] = E[Y_0|D=0] = E[Y_0] \quad \text{under randomization}$$

--

So what happens to *selection bias*?


---
class: MSU

# Randomization

### Under randomization, where treatment is randomly assigned, selection bias is equal to zero in expectation

Remember the definition of mean independence: $E[Y|X] = E[Y]$ for RV's $Y,X$

Applying the same thing to **potential outcomes** of $Y$ and $D$:
- Randomization gives us $(Y_1,Y_0) \perp D$
- $(Y_1, Y_0) \perp D \Rightarrow E[Y_0|D] = E[Y_0]$

--

A comparison of means is then an *unbiased estimate* of the $SATE$

How would we randomize to answer the following with a simple cross-sectional comparison of means
- Effect of energy consumption information on future energy consumption
- Effect of health insurance on health outcomes
- Effect of college education on future earnings

---
class: MSU
# Randomization

Randomization, in it's simplest form, is quite straightforward. If the econometrician<sup>*</sup> can reliably and with certainty assign treatment to individuals, then great!

But even in closely-managed operation, this won't always work. 
  - People are good at finding ways around assignment
  - Even drug trials, which are about as controlled as you can get, are subject to shenanigans.
  - *Endogenous treatment* is the term frequently used for this
    - It means that treatment is determined "within the system" (by an individual affected by the treatment).
    - You will be sick of the term "endogenous" by the end of this semester.

----

.footer[<sup>*</sup> that's you]


---
class: MSU
# A brief detour

### Relating SATE to ATE
- We seem to be able to get to SATE, but what about the ATE?
  - $SATE = E[Y_{1}-Y_{0}|D=1]$
  - $ATE = E[Y_1 - Y_0|D=1]$
  
- If we assume that $E[(Y_1 - Y_0)|D=1] = E[(Y_1 - Y_0)|D=0]$, then the $SATE$ is the same as the $ATE$
- That is, the effect of treatment on the treated is the same as the effect of treatment on the untreated

### This is the *constant effects assumption*

....OK, back to randomization

---
class: MSU
# Randomization

## Randomized Control Trial

When the econometrician is able to randomly decide treatment, we call the study a *randomized control trial* or *RCT*.
- These are *very* common in development economics as they can be done at low-cost in many places.

--

Often, when doing a RCT, we want to make sure we have randomly selected a similar sample into each group (treated, untreated).
- Imagine if you randomly selected people to take part in a smoking campaign, but your "treated" group were mostly older people. If your outcome of interest is "mortality rate", what would happen?


---
class: MSU
# Randomization

### Blocking (stratification)

A *blocked* or *stratified* experiment means we have randomly assigned treatment inside of observable subgroups to ensure balance.
- For example, if our population is 40% college graduates and 60% non-college graduates, and we are assigning treatment to 50% of the participants, we would treat 50% of all college graduates and 50% of all non-college graduates. We would *not* randomly select 50% of all participants.

- "Blocking" because you group observables into "blocks", then select
  - You can block on more than one characteristic: "college graduates over 40", etc..

- This can help ensure balance.

- Of course, this requires being able to assign treatment.


---
class: MSU
# Randomization

```{r BlockingExample1, echo=F, include=T, out.width='80%', fig.subcap='test'}
knitr::include_graphics('http://image.slidesharecdn.com/statschapter5-101115133012-phpapp01/95/stats-chapter-5-40-638.jpg')
```
.footer[Source: Bravo Students]


---
class: MSU
# Review

1. We talked more about selection bias and examples of it.

2. We found that violation MLR.4 led to some pretty big problems.

2. We talked about randomization and how it can alleviate selection bias.

3. We also showed in notation how randomization alleviates selection bias in comparison of means.
  - Because $E[Y_0 | D = 1] = E[Y_0 | D=0]$

4. We defined unbiased and consistent estimators (sample statistics).


